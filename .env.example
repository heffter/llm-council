# =============================================================================
# LLM Council API Keys
# =============================================================================
# At least one provider must be configured for the council and chairman models

# OpenAI (for GPT models)
OPENAI_API_KEY=

# Anthropic (for Claude models)
ANTHROPIC_API_KEY=

# Google (for Gemini models) - accepts GEMINI_API_KEY or GOOGLE_API_KEY
GEMINI_API_KEY=
# GOOGLE_API_KEY=

# Perplexity (for research-enabled models)
PERPLEXITY_API_KEY=

# OpenRouter (proxy for multiple providers)
OPENROUTER_API_KEY=

# =============================================================================
# Model Configuration (provider:model notation)
# =============================================================================
# Format: provider:model
# Supported providers: openai, anthropic, gemini, perplexity, openrouter
#
# Examples:
#   openai:gpt-4.1
#   anthropic:claude-3-5-sonnet-latest
#   gemini:gemini-2.0-pro
#   perplexity:sonar-pro
#   openrouter:anthropic/claude-3-5-sonnet

# Council models (comma-separated list)
# These models participate in Stage 1 (responses) and Stage 2 (rankings)
COUNCIL_MODELS=openai:gpt-4.1,anthropic:claude-3-5-sonnet-latest,gemini:gemini-2.0-pro

# Chairman model (single model)
# This model synthesizes the final response in Stage 3
CHAIRMAN_MODEL=anthropic:claude-3-5-sonnet-latest

# Research model (optional, single model)
# Used for title generation and auxiliary prompts
# If not set, uses the first council model
RESEARCH_MODEL=perplexity:sonar-pro

# =============================================================================
# Storage Configuration
# =============================================================================

# Maximum response size to store (in bytes, default: 262144 = 256KB)
# Responses larger than this will be truncated with a [TRUNCATED] marker
MAX_STORED_RESPONSE_BYTES=262144

# =============================================================================
# Task Master AI Keys (for project management)
# =============================================================================
# These are used by the task-master-ai MCP server, not the LLM Council app
