# Integration Test Pre-Run Checklist

Use this checklist before running integration tests to ensure everything is configured correctly.

## Prerequisites

### 1. Environment Setup

- [ ] Project dependencies installed: `uv sync --all-extras`
- [ ] In project root directory: `/home/heffter/devel/llm-council`
- [ ] `.env` file exists in project root
- [ ] Python 3.10+ available

### 2. API Key Configuration

Check `.env` file and verify API keys are NOT placeholders:

- [ ] **OpenAI** (optional)
  ```bash
  OPENAI_API_KEY=sk-proj-...  # NOT $OPENAI_API_KEY
  ```

- [ ] **Anthropic** (optional)
  ```bash
  ANTHROPIC_API_KEY=sk-ant-...  # NOT $ANTHROPIC_API_KEY
  ```

- [ ] **Google Gemini** (optional)
  ```bash
  GOOGLE_API_KEY=...  # NOT $GOOGLE_API_KEY
  ```

- [ ] **Perplexity** (optional)
  ```bash
  PERPLEXITY_API_KEY=pplx-...  # NOT $PERPLEXITY_API_KEY
  ```

- [ ] **OpenRouter** (optional)
  ```bash
  OPENROUTER_API_KEY=sk-or-v1-...  # NOT $OPENROUTER_API_KEY
  ```

**Note**: At least ONE provider must be configured for tests to run.

### 3. Verify API Keys

Quick verification:

```bash
# Check which providers are configured
grep -E "^(OPENAI|ANTHROPIC|GOOGLE|PERPLEXITY|OPENROUTER)_API_KEY=" .env

# Count configured providers (should be > 0)
grep -E "^(OPENAI|ANTHROPIC|GOOGLE|PERPLEXITY|OPENROUTER)_API_KEY=" .env | grep -v '$' | wc -l
```

### 4. Network Connectivity

- [ ] Internet connection active
- [ ] No firewall blocking API requests
- [ ] No VPN issues affecting connectivity
- [ ] Proxy configured if required

### 5. API Account Status

Check provider dashboards:

- [ ] **OpenAI**: https://platform.openai.com/usage
  - Account active
  - Billing configured
  - API access enabled

- [ ] **Anthropic**: https://console.anthropic.com/settings/keys
  - Account active
  - API key valid

- [ ] **Google**: https://aistudio.google.com/app/apikey
  - API key generated
  - API enabled

- [ ] **Perplexity**: https://www.perplexity.ai/settings/api
  - Account active
  - Credits available

- [ ] **OpenRouter**: https://openrouter.ai/keys
  - Account active
  - Key valid

## Pre-Test Validation

### Quick Syntax Check

```bash
# Verify test file is valid Python
python -m py_compile backend/tests/integration/test_provider_integration.py

# Verify pytest can discover tests
uv run pytest backend/tests/integration/ --collect-only
```

Expected output: `collected 7 items`

### Quick Configuration Test

```bash
# Test that registry can load configuration
python -c "
from dotenv import load_dotenv
load_dotenv()
from backend.providers.registry import ProviderRegistry
reg = ProviderRegistry()
reg.register_from_env()
print('✓ Registry loaded successfully')
print('Configured providers:', [p for p in ['openai', 'anthropic', 'gemini', 'perplexity', 'openrouter'] if reg.is_provider_configured(p)])
"
```

## Running Tests

### Method 1: Automated Script (Recommended)

```bash
./scripts/run_integration_tests.sh
```

✓ Checks configuration automatically
✓ Installs dependencies
✓ Provides detailed output

### Method 2: Pytest Direct

```bash
uv run pytest backend/tests/integration/test_provider_integration.py -v -s
```

### Method 3: Manual Testing

```bash
# Test all configured providers
python scripts/test_single_provider.py

# Test specific provider
python scripts/test_single_provider.py openai gpt-4o-mini
```

## Expected Results

### All Tests Skip

```
7 skipped in 0.02s
```

**Issue**: No API keys configured
**Fix**: Configure at least one provider in `.env`

### Some Tests Skip

```
2 passed, 5 skipped in 5.23s
```

**Status**: Normal - only configured providers are tested
**Action**: No action needed unless you want to test more providers

### All Tests Pass

```
7 passed in 15.42s
```

**Status**: Excellent - all providers working!
**Action**: Proceed with deployment

### Some Tests Fail

```
2 passed, 3 failed, 2 skipped in 10.15s
```

**Issue**: Configuration problem or API issue
**Action**: Review failed test output for specific errors

## Common Issues

### Issue: "Provider not configured"

```
test_openai_integration SKIPPED (OPENAI_API_KEY not configured)
```

**Fix**:
1. Edit `.env`
2. Replace `$OPENAI_API_KEY` with actual key
3. Re-run tests

### Issue: "401 Unauthorized"

```
✗ Test failed: API error 401: Invalid authentication
```

**Fix**:
1. Check API key is correct
2. Verify key hasn't expired
3. Check provider dashboard for key status
4. Regenerate key if needed
5. Update `.env` with new key

### Issue: "Rate limit exceeded"

```
✗ Test failed: Rate limit exceeded (429)
```

**Fix**:
1. Wait 1-5 minutes
2. Check rate limits in provider dashboard
3. Consider upgrading plan if needed

### Issue: "Timeout"

```
✗ Test failed: Request timeout after 30.0s
```

**Fix**:
1. Check internet connectivity
2. Check provider status page
3. Try again in a few minutes
4. Check for proxy/firewall issues

## Post-Test Validation

After successful test run:

- [ ] Review test summary for any warnings
- [ ] Verify expected providers passed
- [ ] Check for any deprecation warnings
- [ ] Note response times for performance baseline
- [ ] Save output for reference if deploying

## Cost Tracking

After running tests, check usage:

- [ ] **OpenAI**: https://platform.openai.com/usage
- [ ] **Anthropic**: https://console.anthropic.com/settings/usage
- [ ] **Google**: Check Cloud Console billing
- [ ] **Perplexity**: Check account credits
- [ ] **OpenRouter**: https://openrouter.ai/activity

Expected cost: < $0.001 per full test run

## Documentation Reference

If you encounter issues, consult:

- **Quick Start**: `/INTEGRATION_TESTING.md`
- **Troubleshooting**: `backend/tests/integration/TESTING_GUIDE.md`
- **Technical Details**: `backend/tests/integration/INTEGRATION_TESTS_SUMMARY.md`
- **Quick Reference**: `backend/tests/integration/README.md`

## Ready to Run?

Verify all checkboxes:

- [ ] At least one provider configured
- [ ] API key is real (not placeholder)
- [ ] Internet connection active
- [ ] Dependencies installed
- [ ] In project root directory

**All checked?** Run: `./scripts/run_integration_tests.sh`

## Emergency Fallback

If everything fails:

1. Check this file for missed steps
2. Review `.env` configuration carefully
3. Test API keys directly in provider dashboard
4. Check provider status pages for outages
5. Review full error output carefully
6. Consult troubleshooting guide: `backend/tests/integration/TESTING_GUIDE.md`

## Success Criteria

Integration tests are successful when:

✓ At least one provider test passes
✓ No unexpected errors
✓ Response content is valid
✓ Request completed within timeout
✓ All configured providers respond correctly

**Tests passing?** You're ready to deploy!
